{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейный SVM \"своими руками\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерируем обучающую и тестовую выборку для экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_classification(\n",
    "    n_samples=10000, n_features=20, \n",
    "    n_classes=2, n_informative=20, \n",
    "    n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print (len(X), len(y))\n",
    "print (len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пишем свой класс для SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "class MySVM(object):\n",
    "    def __init__(self, C=10000, batch_size = 100):\n",
    "        self.C = C # regularization constant\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # f(x) = <w,x> + w_0\n",
    "    def f(self, x):\n",
    "        return np.dot(self.w, x) + self.w0\n",
    "\n",
    "    # a(x) = [f(x) > 0]\n",
    "    def a(self, x):\n",
    "        return 1 if self.f(x) > 0 else -1\n",
    "    \n",
    "    # predicting answers for X_test\n",
    "    def predict(self, X_test):\n",
    "        return np.array([model.a(x) for x in X_test])\n",
    "\n",
    "    # l2-regularizator\n",
    "    def reg(self):\n",
    "        return 1.0 * sum(self.w ** 2) / (2.0 * self.C)\n",
    "\n",
    "    # l2-regularizator derivative\n",
    "    def der_reg(self):\n",
    "        return self.w/self.C\n",
    "\n",
    "    # hinge loss vectorized\n",
    "    def loss(self, x, answer):\n",
    "        return np.vectorize(lambda x_v, answer_v: max([0, 1 - answer_v * self.f(x_v)]),\n",
    "                            signature='(m),()->()')(x, answer)\n",
    "\n",
    "    # hinge loss derivative\n",
    "    def _dl(self, x_v, answer_v):\n",
    "        return -answer_v if 1 - answer_v * self.f(x_v) > 0 else 0.0\n",
    "    \n",
    "    def der_loss(self, x, answer):\n",
    "        return np.vectorize(lambda x_v, answer_v: self._dl(x_v, answer_v), signature=\n",
    "                           '(m),()->()')(x, answer)\n",
    "    \n",
    "    def der_loss_wrt_w(self, x, answer):\n",
    "        #print(self.der_loss(x, answer))\n",
    "        return np.mean((np.multiply(x.T, self.der_loss(x, answer))), axis=1)\n",
    "    \n",
    "    def der_loss_wrt_w0(self, x, answer):\n",
    "        return np.mean(self.der_loss(x, answer))\n",
    "    \n",
    "    def trans_to_01(y):\n",
    "        y[y==-1] = 1\n",
    "        return y\n",
    "    def trans_to_11(y):\n",
    "        y[y == 0] = -1 \n",
    "        return y\n",
    "\n",
    "    # fitting w and w_0 with SGD\n",
    "    def fit(self, X_train, y_train):\n",
    "        y_train = self.trans_to_11(y_train)\n",
    "        dim = len(X_train[0])\n",
    "        self.w = np.random.rand(dim) # initial value for w\n",
    "        self.w0 = np.random.randn() # initial value for w_0\n",
    "        \n",
    "        # 10000 steps is OK for this example\n",
    "        # another variant is to continue iterations while error is still decreasing\n",
    "        loss_a = 1.\n",
    "        delta = 1.\n",
    "        cnt = 0\n",
    "        glob_cnt = 0\n",
    "        #stops if too long\n",
    "        while (cnt<100 or abs(delta/loss_a) > 1e-3) and glob_cnt < 10000:  \n",
    "            \n",
    "            # random example choise\n",
    "            # rand_index = randint(0, len(X_train) - 1,) # generating random index\n",
    "            rand_index = np.random.randint(low=0, high=X_train.shape[0], size=self.batch_size)\n",
    "            x = X_train[rand_index]\n",
    "            y = y_train[rand_index]\n",
    "            \n",
    "            loss_b = self.loss(x, y).sum()\n",
    "\n",
    "            # simple heuristic for step size\n",
    "            \n",
    "            step = 1./(glob_cnt+1)\n",
    "            # w update\n",
    "            #print(self.der_loss_wrt_w(x, y), self.der_reg())\n",
    "            \n",
    "            self.w += step * (-self.der_loss_wrt_w(x, y) - self.der_reg())\n",
    "            \n",
    "            # w_0 update\n",
    "            self.w0 += -step * self.der_loss_wrt_w0(x, y)\n",
    "            \n",
    "            loss_a = self.loss(x, y).sum()\n",
    "            delta = abs(loss_a - loss_b)\n",
    "            if abs(delta/loss_a) > 1e-3: \n",
    "                cnt = 0\n",
    "            else:\n",
    "                cnt+=1\n",
    "            glob_cnt += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пробуем обучить наш классификатор и посмотреть на качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySVM(C=100, batch_size=200)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.w, model.w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkers import svm_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip = svm_checker.Checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip.check(script_path='./checkers/svm_impl_shtanko.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkers import text_classification_params_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip2 = text_classification_params_checker.Checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89395474501857475"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip2.check(params_path='./checkers/txt_params_cls.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
